{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "#url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "#extract_zip(download_url(url, '../data/raw/'), '../data/raw/')\n",
    "\n",
    "movie_path = '../data/raw/ml-10M100K/movies.dat'\n",
    "rating_path = '../data/raw/ml-10M100K/ratings.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user and movie nodes\n",
    "def load_node_dat(path, index_col):\n",
    "    \"\"\"Loads dat containing node information\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        index_col (str): column name of index column\n",
    "\n",
    "    Returns:\n",
    "        dict: mapping of csv row to node id\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=\"::\", names=['Id'], index_col=index_col, usecols=[0])\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    return mapping\n",
    "\n",
    "\n",
    "user_mapping = load_node_dat(rating_path, index_col=0)\n",
    "movie_mapping = load_node_dat(movie_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_mapping.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_dat(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep='::', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "    edge_index = None\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "\n",
    "    return torch.tensor(edge_index)\n",
    "\n",
    "\n",
    "edge_index = load_edge_dat(\n",
    "    rating_path,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 69877, 69877, 69877],\n",
       "        [  120,   183,   228,  ...,  1836,  1944,  2210]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index, num_nodes=edge_index[1].max()+1)\n",
    "    #print('After sampling:', edges)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    #print('After stack:', edges)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sampling: (tensor([23597, 34259, 53120,  ..., 55180, 65604, 60490]), tensor([1239, 9532, 1212,  ..., 1172, 2455, 1340]), tensor([6122, 8661,  821,  ..., 1757, 3435, 6016]))\n",
      "After stack: tensor([[23597, 34259, 53120,  ..., 55180, 65604, 60490],\n",
      "        [ 1239,  9532,  1212,  ...,  1172,  2455,  1340],\n",
      "        [ 6122,  8661,   821,  ...,  1757,  3435,  6016]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10680)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        1024, train_edge_index)\n",
    "neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)\n",
    "\n",
    "model = LightGCN(num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, num_nodes=edge_index[1].max()+1, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.6911, val_loss: 0.26434, val_recall@20: 0.00195, val_precision@20: 0.00076, val_ndcg@20: 0.00129\n",
      "[Iteration 200/10000] train_loss: -1.57133, val_loss: 0.69892, val_recall@20: 0.04148, val_precision@20: 0.01669, val_ndcg@20: 0.03025\n",
      "[Iteration 400/10000] train_loss: -6.28661, val_loss: 1.32011, val_recall@20: 0.09314, val_precision@20: 0.03541, val_ndcg@20: 0.0681\n",
      "[Iteration 600/10000] train_loss: -13.82499, val_loss: 1.9285, val_recall@20: 0.11961, val_precision@20: 0.0407, val_ndcg@20: 0.08464\n",
      "[Iteration 800/10000] train_loss: -22.59883, val_loss: 2.70318, val_recall@20: 0.13251, val_precision@20: 0.04294, val_ndcg@20: 0.09252\n",
      "[Iteration 1000/10000] train_loss: -32.85889, val_loss: 3.54185, val_recall@20: 0.13894, val_precision@20: 0.04381, val_ndcg@20: 0.09742\n",
      "[Iteration 1200/10000] train_loss: -44.95792, val_loss: 4.58797, val_recall@20: 0.14333, val_precision@20: 0.04433, val_ndcg@20: 0.10096\n",
      "[Iteration 1400/10000] train_loss: -58.36752, val_loss: 5.58717, val_recall@20: 0.14555, val_precision@20: 0.0447, val_ndcg@20: 0.10249\n",
      "[Iteration 1600/10000] train_loss: -67.80149, val_loss: 6.65736, val_recall@20: 0.14744, val_precision@20: 0.04497, val_ndcg@20: 0.10433\n",
      "[Iteration 1800/10000] train_loss: -81.80278, val_loss: 7.85117, val_recall@20: 0.14892, val_precision@20: 0.04514, val_ndcg@20: 0.10493\n",
      "[Iteration 2000/10000] train_loss: -97.22784, val_loss: 8.98212, val_recall@20: 0.15038, val_precision@20: 0.04537, val_ndcg@20: 0.10591\n",
      "[Iteration 2200/10000] train_loss: -114.22349, val_loss: 10.12577, val_recall@20: 0.15076, val_precision@20: 0.04542, val_ndcg@20: 0.10631\n",
      "[Iteration 2400/10000] train_loss: -115.98028, val_loss: 11.35609, val_recall@20: 0.15152, val_precision@20: 0.04548, val_ndcg@20: 0.10677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10704/3426889679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# mini batching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n\u001b[0m\u001b[0;32m     12\u001b[0m         BATCH_SIZE, train_edge_index)\n\u001b[0;32m     13\u001b[0m     user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10704/807267140.py\u001b[0m in \u001b[0;36msample_mini_batch\u001b[1;34m(batch_size, edge_index)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muser\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0mitem\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0mitem\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructured_negative_sampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m#print('After sampling:', edges)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\torch_geometric\\utils\\negative_sampling.py\u001b[0m in \u001b[0;36mstructured_negative_sampling\u001b[1;34m(edge_index, num_nodes, contains_neg_self_loops)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mneg_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrest\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[0mrest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36misin\u001b[1;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \"\"\"\n\u001b[0;32m    709\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0m\u001b[0;32m    711\u001b[0m                 invert=invert).reshape(element.shape)\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36min1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[1;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrev_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    #print(neg_item_indices)\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "    neg_items_emb_0 = items_emb_0[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss: -51.76818, test_recall@20: 0.13076, test_precision@20: 0.04728, test_ndcg@20: 0.10368\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "df = pd.read_csv(movie_path)\n",
    "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
    "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
    "\n",
    "user_pos_items = get_user_positive_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(user_id, num_recs):\n",
    "    user = user_mapping[user_id]\n",
    "    e_u = model.users_emb.weight[user]\n",
    "    scores = model.items_emb.weight @ e_u\n",
    "\n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
    "\n",
    "    print()\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some suggested movies for user {user_id}\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some movies that user 1 rated highly\n",
      "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
      "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
      "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
      "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
      "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
      "title: Schindler's List (1993), genres: Drama|War \n",
      "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
      "title: Braveheart (1995), genres: Action|Drama|War \n",
      "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
      "title: American Beauty (1999), genres: Drama|Romance \n",
      "\n",
      "Here are some suggested movies for user 1\n",
      "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
      "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
      "title: Godfather, The (1972), genres: Crime|Drama \n",
      "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
      "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
      "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
      "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
      "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
      "title: Aladdin (1992), genres: Adventure|Animation|Children|Comedy|Musical \n",
      "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n"
     ]
    }
   ],
   "source": [
    "USER_ID = 1\n",
    "NUM_RECS = 10\n",
    "\n",
    "make_predictions(USER_ID, NUM_RECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07921fcac9efc71e32baa62f54cc7cc7703180b766de90eef3b067ead514a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
